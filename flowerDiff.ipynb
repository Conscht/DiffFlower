{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-w4V-jnHx_j"
   },
   "source": [
    "## Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22460,
     "status": "ok",
     "timestamp": 1768774406155,
     "user": {
      "displayName": "Red Lp",
      "userId": "12186890915998845396"
     },
     "user_tz": -60
    },
    "id": "iYizbMTmHis4",
    "outputId": "5028b1a5-951b-4a4d-f34e-c89b73651a0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fiftyone in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (1.11.1)\n",
      "Requirement already satisfied: wandb in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (0.24.0)\n",
      "Requirement already satisfied: open-clip-torch in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: aiofiles in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (25.1.0)\n",
      "Requirement already satisfied: argcomplete in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (3.6.3)\n",
      "Requirement already satisfied: async_lru>=2 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (2.1.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (4.14.3)\n",
      "Requirement already satisfied: boto3 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (1.42.30)\n",
      "Requirement already satisfied: cachetools in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (6.2.4)\n",
      "Requirement already satisfied: dacite<2,>=1.6.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (1.7.0)\n",
      "Requirement already satisfied: dill in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (0.4.0)\n",
      "Requirement already satisfied: Deprecated in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (1.3.1)\n",
      "Requirement already satisfied: ftfy in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (6.3.1)\n",
      "Requirement already satisfied: humanize in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (4.15.0)\n",
      "Requirement already satisfied: hypercorn>=0.13.2 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (0.18.0)\n",
      "Requirement already satisfied: Jinja2>=3 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (3.1.4)\n",
      "Requirement already satisfied: jsonpatch in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (1.33)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (3.10.8)\n",
      "Requirement already satisfied: mongoengine~=0.29.1 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (0.29.1)\n",
      "Requirement already satisfied: motor~=3.6.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (3.6.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (2.0.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (25.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (2.3.3)\n",
      "Requirement already satisfied: Pillow!=11.2.*,>=6.2 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (10.4.0)\n",
      "Requirement already satisfied: plotly>=6.1.1 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (6.5.2)\n",
      "Requirement already satisfied: pprintpp in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (0.4.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (5.9.5)\n",
      "Requirement already satisfied: pymongo~=4.9.2 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (4.9.2)\n",
      "Requirement already satisfied: pytz in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (2025.2)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (6.0.2)\n",
      "Requirement already satisfied: regex in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (2026.1.15)\n",
      "Requirement already satisfied: retrying in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (1.4.2)\n",
      "Requirement already satisfied: rtree in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (1.7.2)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (0.25.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (1.15.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (80.9.0)\n",
      "Requirement already satisfied: sseclient-py<2,>=1.7.2 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (1.9.0)\n",
      "Requirement already satisfied: sse-starlette<1,>=0.10.3 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (0.10.3)\n",
      "Requirement already satisfied: starlette>=0.24.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (0.52.1)\n",
      "Requirement already satisfied: strawberry-graphql>=0.262.4 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (0.289.0)\n",
      "Requirement already satisfied: tabulate in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (0.9.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (4.67.1)\n",
      "Requirement already satisfied: xmltodict in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (1.0.2)\n",
      "Requirement already satisfied: universal-analytics-python3<2,>=1.0.1 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (1.1.1)\n",
      "Requirement already satisfied: pydash in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (8.0.6)\n",
      "Requirement already satisfied: fiftyone-brain<0.22,>=0.21.4 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (0.21.4)\n",
      "Requirement already satisfied: fiftyone-db<2.0,>=0.4 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (1.4.1)\n",
      "Requirement already satisfied: voxel51-eta<0.16,>=0.15.2 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (0.15.2)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from fiftyone) (4.13.0.90)\n",
      "Requirement already satisfied: click>=8.0.1 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from wandb) (8.3.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from wandb) (3.1.46)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from wandb) (4.5.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from wandb) (6.33.4)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from wandb) (2.12.5)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from wandb) (2.49.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from wandb) (4.15.0)\n",
      "Requirement already satisfied: torch>=2.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from open-clip-torch) (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from open-clip-torch) (0.20.1+cu121)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from open-clip-torch) (1.3.2)\n",
      "Requirement already satisfied: safetensors in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from open-clip-torch) (0.7.0)\n",
      "Requirement already satisfied: timm>=1.0.17 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from open-clip-torch) (1.0.24)\n",
      "Requirement already satisfied: colorama in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from click>=8.0.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: exceptiongroup>=1.1.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from hypercorn>=0.13.2->fiftyone) (1.3.1)\n",
      "Requirement already satisfied: h11 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from hypercorn>=0.13.2->fiftyone) (0.16.0)\n",
      "Requirement already satisfied: h2>=4.3.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from hypercorn>=0.13.2->fiftyone) (4.3.0)\n",
      "Requirement already satisfied: priority in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from hypercorn>=0.13.2->fiftyone) (2.0.0)\n",
      "Requirement already satisfied: taskgroup in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from hypercorn>=0.13.2->fiftyone) (0.2.2)\n",
      "Requirement already satisfied: tomli in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from hypercorn>=0.13.2->fiftyone) (2.4.0)\n",
      "Requirement already satisfied: wsproto>=0.14.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from hypercorn>=0.13.2->fiftyone) (1.3.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from Jinja2>=3->fiftyone) (2.1.3)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from plotly>=6.1.1->fiftyone) (2.15.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from pydantic<3->wandb) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from pydantic<3->wandb) (0.4.2)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from pymongo~=4.9.2->fiftyone) (2.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2026.1.4)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from starlette>=0.24.0->fiftyone) (4.12.1)\n",
      "Requirement already satisfied: cross-web>=0.4.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from strawberry-graphql>=0.262.4->fiftyone) (0.4.1)\n",
      "Requirement already satisfied: graphql-core<3.4.0,>=3.2.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from strawberry-graphql>=0.262.4->fiftyone) (3.2.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from strawberry-graphql>=0.262.4->fiftyone) (2.9.0.post0)\n",
      "Requirement already satisfied: filelock in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torch>=2.0->open-clip-torch) (3.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torch>=2.0->open-clip-torch) (3.2.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torch>=2.0->open-clip-torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torch>=2.0->open-clip-torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from sympy==1.13.1->torch>=2.0->open-clip-torch) (1.3.0)\n",
      "Requirement already satisfied: httpx>=0.10.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from universal-analytics-python3<2,>=1.0.1->fiftyone) (0.28.1)\n",
      "Requirement already satisfied: glob2 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from voxel51-eta<0.16,>=0.15.2->fiftyone) (0.7)\n",
      "Requirement already satisfied: jsonlines in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from voxel51-eta<0.16,>=0.15.2->fiftyone) (4.0.0)\n",
      "Requirement already satisfied: paramiko<4,>=3 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from voxel51-eta<0.16,>=0.15.2->fiftyone) (3.5.1)\n",
      "Requirement already satisfied: py7zr in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from voxel51-eta<0.16,>=0.15.2->fiftyone) (1.1.2)\n",
      "Requirement already satisfied: rarfile in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from voxel51-eta<0.16,>=0.15.2->fiftyone) (4.2)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from voxel51-eta<0.16,>=0.15.2->fiftyone) (2.4.0)\n",
      "Requirement already satisfied: tzlocal in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from voxel51-eta<0.16,>=0.15.2->fiftyone) (5.3.1)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from beautifulsoup4->fiftyone) (2.8.2)\n",
      "Requirement already satisfied: botocore<1.43.0,>=1.42.30 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from boto3->fiftyone) (1.42.30)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from boto3->fiftyone) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.17.0,>=0.16.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from boto3->fiftyone) (0.16.0)\n",
      "Requirement already satisfied: wrapt<3,>=1.10 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from Deprecated->fiftyone) (2.0.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from ftfy->fiftyone) (0.2.14)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from huggingface-hub->open-clip-torch) (1.2.0)\n",
      "Requirement already satisfied: shellingham in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from huggingface-hub->open-clip-torch) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from huggingface-hub->open-clip-torch) (0.21.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from jsonpatch->fiftyone) (3.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from matplotlib->fiftyone) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from matplotlib->fiftyone) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from matplotlib->fiftyone) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from matplotlib->fiftyone) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from matplotlib->fiftyone) (3.3.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from pandas->fiftyone) (2025.3)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from scikit-image->fiftyone) (2.37.2)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from scikit-image->fiftyone) (2025.5.10)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from scikit-image->fiftyone) (0.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from scikit-learn->fiftyone) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from scikit-learn->fiftyone) (3.6.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from h2>=4.3.0->hypercorn>=0.13.2->fiftyone) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from h2>=4.3.0->hypercorn>=0.13.2->fiftyone) (4.1.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (1.0.9)\n",
      "Requirement already satisfied: bcrypt>=3.2 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from paramiko<4,>=3->voxel51-eta<0.16,>=0.15.2->fiftyone) (5.0.0)\n",
      "Requirement already satisfied: cryptography>=3.3 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from paramiko<4,>=3->voxel51-eta<0.16,>=0.15.2->fiftyone) (46.0.3)\n",
      "Requirement already satisfied: pynacl>=1.5 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from paramiko<4,>=3->voxel51-eta<0.16,>=0.15.2->fiftyone) (1.6.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from python-dateutil>=2.7->strawberry-graphql>=0.262.4->fiftyone) (1.17.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from jsonlines->voxel51-eta<0.16,>=0.15.2->fiftyone) (25.4.0)\n",
      "Requirement already satisfied: texttable in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from py7zr->voxel51-eta<0.16,>=0.15.2->fiftyone) (1.7.0)\n",
      "Requirement already satisfied: pycryptodomex>=3.20.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from py7zr->voxel51-eta<0.16,>=0.15.2->fiftyone) (3.23.0)\n",
      "Requirement already satisfied: brotli>=1.2.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from py7zr->voxel51-eta<0.16,>=0.15.2->fiftyone) (1.2.0)\n",
      "Requirement already satisfied: backports.zstd>=1.0.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from py7zr->voxel51-eta<0.16,>=0.15.2->fiftyone) (1.3.0)\n",
      "Requirement already satisfied: pyppmd>=1.3.1 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from py7zr->voxel51-eta<0.16,>=0.15.2->fiftyone) (1.3.1)\n",
      "Requirement already satisfied: pybcj>=1.0.6 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from py7zr->voxel51-eta<0.16,>=0.15.2->fiftyone) (1.0.7)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from py7zr->voxel51-eta<0.16,>=0.15.2->fiftyone) (0.2.3)\n",
      "Requirement already satisfied: inflate64>=1.0.4 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from py7zr->voxel51-eta<0.16,>=0.15.2->fiftyone) (1.0.4)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from cryptography>=3.3->paramiko<4,>=3->voxel51-eta<0.16,>=0.15.2->fiftyone) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from cffi>=2.0.0->cryptography>=3.3->paramiko<4,>=3->voxel51-eta<0.16,>=0.15.2->fiftyone) (2.23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -iftyone (c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -iftyone (c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -iftyone (c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ftfy in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (6.3.1)\n",
      "Requirement already satisfied: regex in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (2026.1.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: torchmetrics in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (1.8.2)\n",
      "Requirement already satisfied: torch-fidelity in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from ftfy) (0.2.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torchmetrics) (2.0.2)\n",
      "Requirement already satisfied: packaging>17.1 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torchmetrics) (25.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torchmetrics) (2.5.1+cu121)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torchmetrics) (0.15.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torch-fidelity) (10.4.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torch-fidelity) (1.15.3)\n",
      "Requirement already satisfied: torchvision in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torch-fidelity) (0.20.1+cu121)\n",
      "Requirement already satisfied: setuptools in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (80.9.0)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (3.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from jinja2->torch>=2.0.0->torchmetrics) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -iftyone (c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -iftyone (c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -iftyone (c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to c:\\users\\conscht\\appdata\\local\\temp\\pip-req-build-dgwreqpu\n",
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: ftfy in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from clip==1.0) (6.3.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from clip==1.0) (25.0)\n",
      "Requirement already satisfied: regex in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from clip==1.0) (2026.1.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from clip==1.0) (4.67.1)\n",
      "Requirement already satisfied: torch in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from clip==1.0) (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from clip==1.0) (0.20.1+cu121)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from ftfy->clip==1.0) (0.2.14)\n",
      "Requirement already satisfied: filelock in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torch->clip==1.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torch->clip==1.0) (4.15.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torch->clip==1.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torch->clip==1.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torch->clip==1.0) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torch->clip==1.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from sympy==1.13.1->torch->clip==1.0) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torchvision->clip==1.0) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torchvision->clip==1.0) (10.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from tqdm->clip==1.0) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from jinja2->torch->clip==1.0) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -iftyone (c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages)\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git 'C:\\Users\\Conscht\\AppData\\Local\\Temp\\pip-req-build-dgwreqpu'\n",
      "WARNING: Ignoring invalid distribution -iftyone (c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -iftyone (c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: umap-learn in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (0.5.11)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from umap-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.3.1 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from umap-learn) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn>=1.6 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from umap-learn) (1.7.2)\n",
      "Requirement already satisfied: numba>=0.51.2 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from umap-learn) (0.63.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from umap-learn) (0.6.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from umap-learn) (4.67.1)\n",
      "Requirement already satisfied: llvmlite<0.47,>=0.46.0dev0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from numba>=0.51.2->umap-learn) (0.46.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from pynndescent>=0.5->umap-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from scikit-learn>=1.6->umap-learn) (3.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from tqdm->umap-learn) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -iftyone (c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -iftyone (c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -iftyone (c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.5.1+cu121\n",
      "Uninstalling torch-2.5.1+cu121:\n",
      "  Successfully uninstalled torch-2.5.1+cu121\n",
      "Found existing installation: torchvision 0.20.1+cu121\n",
      "Uninstalling torchvision-0.20.1+cu121:\n",
      "  Successfully uninstalled torchvision-0.20.1+cu121\n",
      "Found existing installation: torchaudio 2.5.1+cu121\n",
      "Uninstalling torchaudio-2.5.1+cu121:\n",
      "  Successfully uninstalled torchaudio-2.5.1+cu121\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp310-cp310-win_amd64.whl (2449.4 MB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp310-cp310-win_amd64.whl (6.1 MB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp310-cp310-win_amd64.whl (4.1 MB)\n",
      "Requirement already satisfied: filelock in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -iftyone (c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -iftyone (c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -iftyone (c:\\users\\conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "!pip install --upgrade fiftyone wandb open-clip-torch nbformat\n",
    "!pip install ftfy regex tqdm torchmetrics torch-fidelity\n",
    "!pip install git+https://github.com/openai/CLIP.git\n",
    "\n",
    "# Install UMAP for FiftyOne Brain visualization\n",
    "!pip install umap-learn\n",
    "\n",
    "# --- FIX: Re-install PyTorch with CUDA support ---\n",
    "# 1. Uninstall current CPU version\n",
    "!pip uninstall -y torch torchvision torchaudio\n",
    "\n",
    "# 2. Install GPU version (CUDA 12.1)\n",
    "# If this doesn't work, try cu118\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6ZanO1vH58z"
   },
   "source": [
    "## Part 1: Image Generation and Emebdding Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1768774406219,
     "user": {
      "displayName": "Red Lp",
      "userId": "12186890915998845396"
     },
     "user_tz": -60
    },
    "id": "8biQUK45iDUu",
    "outputId": "c3d6a698-10e3-464e-e13e-ebfa1104ad9e"
   },
   "outputs": [],
   "source": [
    "# cd drive/MyDrive/Hands-on-CV3  # Commented out Google Colab specific path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3009,
     "status": "ok",
     "timestamp": 1768774409231,
     "user": {
      "displayName": "Red Lp",
      "userId": "12186890915998845396"
     },
     "user_tz": -60
    },
    "id": "vD8D59RoH-64"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Conscht\\anaconda3\\envs\\pointllm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.5.1+cu121\n",
      "Utils imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Import our new utility module\n",
    "import utils\n",
    "from utils import ClassicLeNet5, CustomTorchImageDataset, train_epoch, val_epoch, evaluate_idk_performance\n",
    "\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(\"Utils imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 8915,
     "status": "ok",
     "timestamp": 1768774418178,
     "user": {
      "displayName": "Red Lp",
      "userId": "12186890915998845396"
     },
     "user_tz": -60
    },
    "id": "y241swK7fkou"
   },
   "outputs": [],
   "source": [
    "import clip\n",
    "\n",
    "clip.available_models()\n",
    "clip_model, clip_preprocess = clip.load(\"ViT-B/32\")\n",
    "clip_model.eval()\n",
    "CLIP_FEATURES = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qRaMxnfynLt"
   },
   "source": [
    "Sanity Check of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "executionInfo": {
     "elapsed": 12409,
     "status": "ok",
     "timestamp": 1768774430592,
     "user": {
      "displayName": "Red Lp",
      "userId": "12186890915998845396"
     },
     "user_tz": -60
    },
    "id": "OCW8a1ZNupNR",
    "outputId": "9645ee38-8a12-45c1-c033-ff294da44c36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Conscht\\AppData\\Local\\Temp\\ipykernel_24796\\2093297480.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(weights_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights from flowerDiff.pth\n",
      "Generating 3 test images with Guidance Scale w=4.0...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "N = 200     # Based on ressource limiations\n",
    "BATCH_SIZE = 8\n",
    "IMG_SIZE = 32\n",
    "IMG_CH = 3\n",
    "INPUT_SIZE = (IMG_CH, IMG_SIZE, IMG_SIZE)\n",
    "B_start = 0.0001\n",
    "B_end = 0.02\n",
    "NUM_STEPS = 400\n",
    "\n",
    "# Define paths\n",
    "project_root = Path.cwd()\n",
    "sys.path.append(str(Path(\".\").resolve()))\n",
    "\n",
    "# Helper paths (Found in utilis/utils)\n",
    "# Adding both parent layers in case of nested imports\n",
    "sys.path.append(str(project_root / \"utilis\"))\n",
    "sys.path.append(str(project_root / \"utilis\" / \"utils\"))\n",
    "\n",
    "OUT_DIR = Path(\"generated_flowers\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- 2. MODEL SETUP ---\n",
    "\n",
    "try:\n",
    "    # Try importing directly\n",
    "    if 'UNet_utils' not in globals():\n",
    "        import UNet_utils\n",
    "    if 'ddpm_utils' not in globals():\n",
    "        import ddpm_utils\n",
    "        \n",
    "    model = UNet_utils.UNet(\n",
    "        T=400, img_ch=3, img_size=32, down_chs=(256, 256, 512),\n",
    "        t_embed_dim=8, c_embed_dim=512\n",
    "    ).to(device)\n",
    "\n",
    "    # Ensure the path is correct relative to your environment\n",
    "    weights_path = 'flowerDiff.pth' \n",
    "    \n",
    "    if Path(weights_path).exists():\n",
    "        model.load_state_dict(torch.load(weights_path, map_location=device))\n",
    "        print(f\"Loaded weights from {weights_path}\")\n",
    "    else:\n",
    "        print(f\"Warning: Weights file {weights_path} not found. Model is using random weights.\")\n",
    "        \n",
    "    model.eval()\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing helper modules: {e}\")\n",
    "    print(f\"Current sys.path: {sys.path}\")\n",
    "except NameError as e:\n",
    "    print(f\"NameError: {e}. Check if UNet_utils/ddpm_utils are defined.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "# 1. Define Test Prompts\n",
    "test_prompts = [\n",
    "    \"A photo of a red rose\",\n",
    "    \"A photo of a white daisy\",\n",
    "    \"A photo of a yellow sunflower\"\n",
    "]\n",
    "\n",
    "print(\"Generating 3 test images with Guidance Scale w=4.0...\")\n",
    "\n",
    "# 2. Generate\n",
    "if 'clip' in globals() and 'clip_model' in globals():\n",
    "    try:\n",
    "        text_tokens = clip.tokenize(test_prompts).to(device)\n",
    "        c = clip_model.encode_text(text_tokens).float()\n",
    "\n",
    "        B = torch.linspace(B_start, B_end, NUM_STEPS).to(device)\n",
    "        ddpm = ddpm_utils.DDPM(B, device)\n",
    "\n",
    "        def _to_01(x: torch.Tensor) -> torch.Tensor:\n",
    "            if x.min() < 0:\n",
    "                x = (x + 1) / 2.0\n",
    "            return x.clamp(0, 1)\n",
    "\n",
    "\n",
    "        # Sample\n",
    "        x_test, _ = ddpm_utils.sample_w(\n",
    "            model,\n",
    "            ddpm,\n",
    "            INPUT_SIZE,\n",
    "            NUM_STEPS,\n",
    "            c,\n",
    "            device,\n",
    "            w_tests=[1] #\n",
    "        )\n",
    "        # 3. Visualize Results\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        for i in range(len(test_prompts)):\n",
    "            # Convert from [C, H, W] to [H, W, C] for plotting\n",
    "            img_tensor = _to_01(x_test[i]).cpu()\n",
    "            img_np = img_tensor.permute(1, 2, 0).numpy()\n",
    "\n",
    "            plt.subplot(1, 3, i+1)\n",
    "            plt.imshow(img_np)\n",
    "            plt.title(f\"Prompt: {test_prompts[i]}\\n(Guidance w=2.0)\")\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during generation/visualization: {e}\")\n",
    "else:\n",
    "    print(\"CLIP model not loaded. Please run the previous cell setup.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MniDa7z8IBy5",
    "outputId": "7238c36a-622a-470f-f241-895957bd2b2a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Conscht\\AppData\\Local\\Temp\\ipykernel_24796\\2114849695.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(weights_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights from flowerDiff.pth\n",
      "Moving CLIP model to selected device...\n",
      "Starting generation of 200 images...\n",
      "Generated 8/200\n",
      "Generated 16/200\n",
      "Generated 24/200\n",
      "Generated 32/200\n",
      "Generated 40/200\n",
      "Generated 48/200\n",
      "Generated 56/200\n",
      "Generated 64/200\n",
      "Generated 72/200\n",
      "Generated 80/200\n",
      "Generated 88/200\n",
      "Generated 96/200\n",
      "Generated 104/200\n",
      "Generated 112/200\n",
      "Generated 120/200\n",
      "Generated 128/200\n",
      "Generated 136/200\n",
      "Generated 144/200\n",
      "Generated 152/200\n",
      "Generated 160/200\n",
      "Generated 168/200\n",
      "Generated 176/200\n",
      "Generated 184/200\n",
      "Generated 192/200\n",
      "Generated 200/200\n",
      "Done!\n",
      "Generated: 200 Embeddings: (200, 512)\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies if missing\n",
    "try:\n",
    "    import einops\n",
    "except ImportError:\n",
    "    !pip install einops\n",
    "    import einops\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# --- 1. CONFIGURATION\n",
    "N = 200     # Based on ressource limiations\n",
    "BATCH_SIZE = 8\n",
    "IMG_SIZE = 32\n",
    "IMG_CH = 3\n",
    "INPUT_SIZE = (IMG_CH, IMG_SIZE, IMG_SIZE)\n",
    "B_start = 0.0001\n",
    "B_end = 0.02\n",
    "NUM_STEPS = 400\n",
    "\n",
    "# Define paths\n",
    "project_root = Path.cwd()\n",
    "sys.path.append(str(Path(\".\").resolve()))\n",
    "# Add utils path\n",
    "sys.path.append(str(project_root / \"utilis\" / \"utils\"))\n",
    "\n",
    "# Import helper modules\n",
    "try:\n",
    "    import UNet_utils\n",
    "    import ddpm_utils\n",
    "except ImportError as e:\n",
    "    raise ImportError(f\"Error importing helper modules: {e}. 'utilis/utils' likely missing from path.\") from e\n",
    "\n",
    "OUT_DIR = Path(\"generated_flowers\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- DEVICE SELECTION ---\n",
    "# Force GPU usage if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "model = UNet_utils.UNet(\n",
    "    T=400, img_ch=3, img_size=32, down_chs=(256, 256, 512),\n",
    "    t_embed_dim=8, c_embed_dim=512\n",
    ").to(device)\n",
    "\n",
    "# Ensure the path is correct relative to your environment\n",
    "weights_path = 'flowerDiff.pth' \n",
    "    \n",
    "if Path(weights_path).exists():\n",
    "    model.load_state_dict(torch.load(weights_path, map_location=device))\n",
    "    print(f\"Loaded weights from {weights_path}\")\n",
    "else:\n",
    "    print(f\"Warning: {weights_path} not found. Using random weights.\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Check and move CLIP model if it exists globally\n",
    "if 'clip_model' in globals():\n",
    "    print(\"Moving CLIP model to selected device...\")\n",
    "    clip_model = clip_model.to(device)\n",
    "\n",
    "# DDPM Setup\n",
    "B = torch.linspace(B_start, B_end, NUM_STEPS).to(device)\n",
    "ddpm = ddpm_utils.DDPM(B, device)\n",
    "\n",
    "# --- 3. HOOKS FOR EMBEDDINGS ---\n",
    "embeddings_storage = {}\n",
    "\n",
    "def get_embedding_hook(name):\n",
    "    def hook(model, input, output):\n",
    "        embeddings_storage[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "# Register hook on down2\n",
    "_ = model.down2.register_forward_hook(get_embedding_hook('down2'))\n",
    "\n",
    "# --- 4. HELPER FUNCTIONS ---\n",
    "def _to_01(x: torch.Tensor) -> torch.Tensor:\n",
    "    if x.min() < 0:\n",
    "        x = (x + 1) / 2.0\n",
    "    return x.clamp(0, 1)\n",
    "\n",
    "def cycle_prompts(prompts, n):\n",
    "    \"\"\"Cycles through the prompt list to match the requested number of images.\"\"\"\n",
    "    return (prompts * ((n + len(prompts) - 1) // len(prompts)))[:n]\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample_flowers_with_embeddings(prompt_list, w=2):\n",
    "    embeddings_storage.clear()\n",
    "\n",
    "    # Ensure CLIP model is on the correct device\n",
    "    if next(clip_model.parameters()).device != device:\n",
    "        clip_model.to(device)\n",
    "\n",
    "    text_tokens = clip.tokenize(prompt_list).to(device)\n",
    "    c = clip_model.encode_text(text_tokens).float()\n",
    "\n",
    "    x_gen, _ = ddpm_utils.sample_w(\n",
    "        model,\n",
    "        ddpm,\n",
    "        INPUT_SIZE,\n",
    "        NUM_STEPS,\n",
    "        c,\n",
    "        device,\n",
    "        w_tests=[w]\n",
    "    )\n",
    "\n",
    "    down2 = embeddings_storage[\"down2\"]          # [B, C, H, W]\n",
    "    down2_vec = down2.mean(dim=(2, 3))           # [B, C] Global Average Pooling\n",
    "\n",
    "    x_gen = x_gen[:len(prompt_list)]\n",
    "    down2_vec = down2_vec[:len(prompt_list)]\n",
    "\n",
    "    return x_gen, down2_vec\n",
    "\n",
    "# --- 5. MAIN GENERATION LOOP ---\n",
    "text_prompts = [\n",
    "    \"A photo of a red rose\",\n",
    "    \"A photo of a white daisy\",\n",
    "    \"A photo of a yellow sunflower\"\n",
    "]\n",
    "\n",
    "text_prompts_seed = text_prompts\n",
    "all_prompts = cycle_prompts(text_prompts_seed, N)\n",
    "\n",
    "image_paths = []\n",
    "prompt_per_image = []\n",
    "unet_embs = []\n",
    "\n",
    "print(f\"Starting generation of {N} images...\")\n",
    "\n",
    "idx = 0\n",
    "while idx < N:\n",
    "    # Slice the prompts for this batch\n",
    "    batch_prompts = all_prompts[idx : idx + BATCH_SIZE]\n",
    "\n",
    "    # Generate\n",
    "    x_gen, emb_vec = sample_flowers_with_embeddings(batch_prompts)\n",
    "\n",
    "    # Process results\n",
    "    x01 = _to_01(x_gen).cpu()\n",
    "    emb_np = emb_vec.detach().cpu().numpy()\n",
    "\n",
    "    for j in range(len(batch_prompts)):\n",
    "        current_id = idx + j\n",
    "        fp = OUT_DIR / f\"gen_{current_id:06d}.png\"\n",
    "\n",
    "        save_image(x01[j], fp)\n",
    "\n",
    "        image_paths.append(str(fp))\n",
    "        prompt_per_image.append(batch_prompts[j])\n",
    "        unet_embs.append(emb_np[j].astype(np.float32))\n",
    "\n",
    "    idx += len(batch_prompts)\n",
    "    print(f\"Generated {idx}/{N}\")\n",
    "\n",
    "unet_embs_np = np.stack(unet_embs, axis=0)  # [N, C]\n",
    "print(\"Done!\")\n",
    "print(\"Generated:\", len(image_paths), \"Embeddings:\", unet_embs_np.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVkPPrNTISS9"
   },
   "source": [
    "## Part 2: Evaluation with CLIP Score and Frechet Inception Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ul_RZsCIbcHF"
   },
   "source": [
    "First download the data for comparson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1inW9XQNbbKk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already exists at C:\\Users\\Conscht\\MNIST_Curation_Repo\\flower_photos\n",
      "Found 3670 images in dataset.\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# 1. Define URL and Paths\n",
    "dataset_url = \"http://download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "archive_path = Path(\"flower_photos.tgz\")\n",
    "data_dir = Path(\"flower_photos\")  # This is where images will be extracted\n",
    "\n",
    "# 2. Download\n",
    "if not archive_path.exists():\n",
    "    print(f\"Downloading TF-Flowers from {dataset_url}...\")\n",
    "    urllib.request.urlretrieve(dataset_url, archive_path)\n",
    "    print(\"Download complete.\")\n",
    "\n",
    "# 3. Extract\n",
    "if not data_dir.exists():\n",
    "    print(\"Extracting images...\")\n",
    "    with tarfile.open(archive_path, \"r:gz\") as tar:\n",
    "        tar.extractall()\n",
    "    print(f\"Extracted to {data_dir.resolve()}\")\n",
    "else:\n",
    "    print(f\"Data already exists at {data_dir.resolve()}\")\n",
    "\n",
    "# 4. Quick verification\n",
    "jpg_count = len(list(data_dir.glob(\"**/*.jpg\")))\n",
    "print(f\"Found {jpg_count} images in dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Z2q_-4rZbm7g"
   },
   "outputs": [],
   "source": [
    "# OLD\n",
    "# real_data_dir = Path(\"flower_data/train\")\n",
    "\n",
    "# NEW (Points to the downloaded TF-Flowers)\n",
    "real_data_dir = Path(\"flower_photos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eg6CTfrrulea"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZOlEHxRpIerX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting CLIP Evaluation ---\n",
      "Evaluated 0 images...\n",
      "Evaluated 50 images...\n",
      "Evaluated 100 images...\n",
      "Evaluated 150 images...\n",
      "Mean CLIP Score: 0.26887455880641936\n",
      "\n",
      "--- Starting FID Evaluation ---\n"
     ]
    }
   ],
   "source": [
    "import open_clip\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy.linalg import sqrtm\n",
    "from pathlib import Path\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. CLIP Score Evaluation\n",
    "# ==========================================\n",
    "print(\"--- Starting CLIP Evaluation ---\")\n",
    "\n",
    "# FIX 1: Load model ONCE outside the loop\n",
    "# Note: 'ViT-B-32' is standard, but check if you need 'ViT-L-14' for better accuracy if VRAM allows.\n",
    "clip_model_name = \"ViT-B-32\"\n",
    "clip_pretrained = \"laion2b_s34b_b79k\"\n",
    "\n",
    "try:\n",
    "    model_clip, _, preprocess_clip = open_clip.create_model_and_transforms(clip_model_name, pretrained=clip_pretrained)\n",
    "    model_clip = model_clip.to(device).eval()\n",
    "    tokenizer = open_clip.get_tokenizer(clip_model_name)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading OpenCLIP: {e}. Make sure open_clip_torch is installed.\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def calculate_single_clip_score(image_path, text_prompt):\n",
    "    # Load and Preprocess\n",
    "    image = preprocess_clip(Image.open(image_path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
    "    text = tokenizer([text_prompt]).to(device)\n",
    "\n",
    "    # Encode\n",
    "    image_features = model_clip.encode_image(image)\n",
    "    text_features = model_clip.encode_text(text)\n",
    "\n",
    "    # Normalize\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    # Dot product\n",
    "    return float((image_features @ text_features.T).item())\n",
    "\n",
    "# FIX 2: Use 'prompt_per_image' (length 200) instead of 'text_prompts' (length 3)\n",
    "# Ensure image_paths and prompt_per_image exist from the previous step\n",
    "if 'prompt_per_image' not in locals():\n",
    "    print(\"Warning: prompt_per_image not found. Using text_prompts (this limits eval to 3 images).\")\n",
    "    prompt_list_to_use = text_prompts\n",
    "else:\n",
    "    prompt_list_to_use = prompt_per_image\n",
    "\n",
    "# Calculate scores\n",
    "clip_scores = []\n",
    "for i, (p, t) in enumerate(zip(image_paths, prompt_list_to_use)):\n",
    "    score = calculate_single_clip_score(p, t)\n",
    "    clip_scores.append(score)\n",
    "    if i % 50 == 0: print(f\"Evaluated {i} images...\")\n",
    "\n",
    "print(\"Mean CLIP Score:\", float(np.mean(clip_scores)))\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 2. FID (Frechet Inception Distance)\n",
    "# ==========================================\n",
    "print(\"\\n--- Starting FID Evaluation ---\")\n",
    "\n",
    "# FIX 3: Add Normalization. Inception expects ImageNet mean/std.\n",
    "inception_transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load Inception V3\n",
    "inception = models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1, transform_input=False)\n",
    "inception.fc = torch.nn.Identity()  # Remove classification layer\n",
    "inception = inception.to(device).eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_inception_embeddings(image_paths, batch_size=32):\n",
    "    embs = []\n",
    "    # Batch processing for speed\n",
    "    for i in range(0, len(image_paths), batch_size):\n",
    "        batch_paths = image_paths[i:i+batch_size]\n",
    "\n",
    "        imgs = []\n",
    "        valid_batch = True\n",
    "        for p in batch_paths:\n",
    "            try:\n",
    "                imgs.append(inception_transform(Image.open(p).convert(\"RGB\")))\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {p}: {e}\")\n",
    "                valid_batch = False\n",
    "\n",
    "        if not valid_batch or len(imgs) == 0: continue\n",
    "\n",
    "        x = torch.stack(imgs).to(device)\n",
    "        y = inception(x)  # [B, 2048]\n",
    "        embs.append(y.cpu().numpy())\n",
    "\n",
    "    if len(embs) > 0:\n",
    "        return np.concatenate(embs, axis=0)\n",
    "    else:\n",
    "        return np.array([])\n",
    "\n",
    "def calculate_fid(real_embeddings, gen_embeddings):\n",
    "    # Safety check for small N\n",
    "    if len(real_embeddings) == 0 or len(gen_embeddings) == 0:\n",
    "        return float('inf')\n",
    "\n",
    "    mu1, sigma1 = real_embeddings.mean(axis=0), np.cov(real_embeddings, rowvar=False)\n",
    "    mu2, sigma2 = gen_embeddings.mean(axis=0), np.cov(gen_embeddings, rowvar=False)\n",
    "\n",
    "    ssdiff = np.sum((mu1 - mu2) ** 2)\n",
    "\n",
    "    # Calculate sqrt of product of covariances\n",
    "    covmean = sqrtm(sigma1.dot(sigma2))\n",
    "\n",
    "    # Check for numerical instability\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "\n",
    "    fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "    return float(fid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "YA-xu5p5bsDK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings... Real: 200, Gen: 200\n",
      "FID Score: 339.5110\n"
     ]
    }
   ],
   "source": [
    "# --- Define Paths ---\n",
    "gen_dir = Path(\"generated_flowers\")\n",
    "\n",
    "# Point to the extracted gt F-Flowers folder\n",
    "real_data_dir = Path(\"flower_photos\")\n",
    "\n",
    "# Collect paths (TF-Flowers has subfolders)\n",
    "gen_paths  = sorted([str(p) for p in gen_dir.glob(\"*.png\")])\n",
    "real_paths = sorted([str(p) for p in real_data_dir.glob(\"**/*.jpg\")])\n",
    "\n",
    "# Limit real images to match the number of generated images (fair comparison)\n",
    "# If we generated 200 images, we select the first 200 real images.\n",
    "if len(real_paths) > len(gen_paths):\n",
    "    real_paths = real_paths[:len(gen_paths)]\n",
    "\n",
    "print(f\"Computing embeddings... Real: {len(real_paths)}, Gen: {len(gen_paths)}\")\n",
    "\n",
    "if len(real_paths) > 0 and len(gen_paths) > 0:\n",
    "    real_emb = get_inception_embeddings(real_paths)\n",
    "    gen_emb  = get_inception_embeddings(gen_paths)\n",
    "\n",
    "    fid_value = calculate_fid(real_emb, gen_emb)\n",
    "    print(f\"FID Score: {fid_value:.4f}\")\n",
    "else:\n",
    "    print(\"Skipping FID: Real or Generated image lists are empty. Check your paths.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9poQ0C7IgQP"
   },
   "source": [
    "## Part 3: Embedding Analysis with FiftyOne Brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "YIziFrKuIjqT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting FiftyOne Setup ---\n",
      " 100% || 200/200 [249.3ms elapsed, 0s remaining, 808.8 samples/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:eta.core.utils: 100% || 200/200 [249.3ms elapsed, 0s remaining, 808.8 samples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset with 200 samples.\n",
      "Computing uniqueness...\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.internal.core.utils:Computing embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% || 200/200 [695.5ms elapsed, 0s remaining, 288.3 samples/s]      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:eta.core.utils: 100% || 200/200 [695.5ms elapsed, 0s remaining, 288.3 samples/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing uniqueness...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.internal.core.uniqueness:Computing uniqueness...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniqueness computation complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.internal.core.uniqueness:Uniqueness computation complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing representativeness...\n",
      "Computing representativeness...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.internal.core.representativeness:Computing representativeness...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing clusters for 200 embeddings; this may take awhile...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.internal.core.representativeness:Computing clusters for 200 embeddings; this may take awhile...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representativeness computation complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.internal.core.representativeness:Representativeness computation complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing UMAP visualization...\n",
      "Generating visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.visualization:Generating visualization...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP( verbose=True)\n",
      "Mon Jan 19 02:00:17 2026 Construct fuzzy simplicial set\n",
      "Mon Jan 19 02:00:17 2026 Finding Nearest Neighbors\n",
      "Mon Jan 19 02:00:21 2026 Finished Nearest Neighbor Search\n",
      "Mon Jan 19 02:00:23 2026 Construct embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed: 100%|  500/500 [00:01]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  0  /  500 epochs\n",
      "\tcompleted  50  /  500 epochs\n",
      "\tcompleted  100  /  500 epochs\n",
      "\tcompleted  150  /  500 epochs\n",
      "\tcompleted  200  /  500 epochs\n",
      "\tcompleted  250  /  500 epochs\n",
      "\tcompleted  300  /  500 epochs\n",
      "\tcompleted  350  /  500 epochs\n",
      "\tcompleted  400  /  500 epochs\n",
      "\tcompleted  450  /  500 epochs\n",
      "Mon Jan 19 02:00:24 2026 Finished embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=True&subscription=cb530b9e-5201-4b0b-af0d-82699c2b8e77\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x28dfd2f8d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.brain as fob\n",
    "import numpy as np\n",
    "\n",
    "print(\"--- Starting FiftyOne Setup ---\")\n",
    "\n",
    "# 1. Clean up previous runs\n",
    "dataset_name = \"generated_flowers_with_embeddings\"\n",
    "if dataset_name in fo.list_datasets():\n",
    "    fo.delete_dataset(dataset_name)\n",
    "\n",
    "dataset = fo.Dataset(name=dataset_name)\n",
    "\n",
    "# 2. Add Samples\n",
    "samples = []\n",
    "\n",
    "for fp, prompt, score, emb in zip(image_paths, prompt_per_image, clip_scores, unet_embs_np):\n",
    "    s = fo.Sample(filepath=fp)\n",
    "\n",
    "    # Store metadata\n",
    "    s[\"prompt\"] = fo.Classification(label=prompt)\n",
    "    s[\"clip_score\"] = float(score)\n",
    "    s[\"unet_embedding\"] = emb.tolist()  # FiftyOne expects lists, not numpy arrays\n",
    "\n",
    "    samples.append(s)\n",
    "\n",
    "dataset.add_samples(samples)\n",
    "dataset.save()\n",
    "print(f\"Created dataset with {len(dataset)} samples.\")\n",
    "\n",
    "# 3. Brain Computations (Uniqueness & Representativeness)\n",
    "print(\"Computing uniqueness...\")\n",
    "fob.compute_uniqueness(dataset)\n",
    "\n",
    "print(\"Computing representativeness...\")\n",
    "fob.compute_representativeness(dataset, embeddings=\"unet_embedding\")\n",
    "\n",
    "# 4. Visualization (UMAP)\n",
    "print(\"Computing UMAP visualization...\")\n",
    "# This generates a 2D scatter plot of your embeddings in the App\n",
    "fob.compute_visualization(\n",
    "    dataset,\n",
    "    embeddings=\"unet_embedding\",\n",
    "    method=\"umap\",\n",
    "    brain_key=\"umap_vis\"\n",
    ")\n",
    "\n",
    "# 5. Launch App\n",
    "session = fo.launch_app(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-DMAbqZ3a5H"
   },
   "source": [
    "The results look quite nice. While they are are a bit noisy, it is clear that using the guidance scale, every image is clearly dividable in one of the 3 possible classes!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cMdaoFqmMajK"
   },
   "outputs": [],
   "source": [
    "## Part 4 - W&B logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9cXHDBUusDq1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to verify login in offline mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting WandB Logging ---\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>c:\\Users\\Conscht\\MNIST_Curation_Repo\\wandb\\offline-run-20260119_020405-5wi1hsm7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating WandB Table...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_clip_mean</td><td></td></tr><tr><td>global_fid_score</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_clip_mean</td><td>0.26887</td></tr><tr><td>global_fid_score</td><td>339.51098</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br><code>wandb sync c:\\Users\\Conscht\\MNIST_Curation_Repo\\wandb\\offline-run-20260119_020405-5wi1hsm7<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\offline-run-20260119_020405-5wi1hsm7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB logging complete  Check your dashboard!\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "print(\"--- Starting WandB Logging ---\")\n",
    "\n",
    "# 1. Login\n",
    "wandb.login()\n",
    "\n",
    "# 2. Initialize Run\n",
    "run = wandb.init(\n",
    "    project=\"Hands-on-CV-Project3\",\n",
    "    name=\"flower_generation_run\",\n",
    "    config={\n",
    "        \"num_steps\": NUM_STEPS,\n",
    "        \"beta_start\": B_start,\n",
    "        \"beta_end\": B_end,\n",
    "        \"num_prompts\": len(text_prompts),\n",
    "        \"total_images\": N,\n",
    "        \"model_architecture\": \"UNet_32x32\",\n",
    "        \"guidance_scale\": 2.0,\n",
    "    },\n",
    ")\n",
    "\n",
    "# 3. Log Scalar Metrics (Summary)\n",
    "run.log({\n",
    "    \"global_clip_mean\": float(np.mean(clip_scores)),\n",
    "    \"global_fid_score\": fid_value,\n",
    "})\n",
    "\n",
    "# 4. Create Rich Table\n",
    "# We iterate over the FiftyOne dataset to ensure we get the computed scores\n",
    "table = wandb.Table(columns=[\n",
    "    \"generated_image\",\n",
    "    \"prompt\",\n",
    "    \"clip_score\",\n",
    "    \"uniqueness_score\",\n",
    "    \"representativeness_score\"\n",
    "])\n",
    "\n",
    "print(\"Populating WandB Table...\")\n",
    "\n",
    "for s in dataset:\n",
    "    # Safely get brain scores (default to 0.0 if calculation failed)\n",
    "    u_score = s[\"uniqueness\"] if \"uniqueness\" in s else 0.0\n",
    "    r_score = s[\"representativeness\"] if \"representativeness\" in s else 0.0\n",
    "\n",
    "    table.add_data(\n",
    "        wandb.Image(s.filepath),\n",
    "        s[\"prompt\"].label,\n",
    "        s[\"clip_score\"],\n",
    "        u_score,\n",
    "        r_score\n",
    "    )\n",
    "\n",
    "# 5. Log Table and Finish\n",
    "run.log({\"generation_results\": table})\n",
    "run.finish()\n",
    "\n",
    "print(\"WandB logging complete  Check your dashboard!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8hReWM56RCo"
   },
   "source": [
    "Publish the data on HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-sAohqqt6QYi"
   },
   "outputs": [],
   "source": [
    "!pip install huggingface_hub\n",
    "\n",
    "import fiftyone as fo\n",
    "from huggingface_hub import login, HfApi\n",
    "import os\n",
    "\n",
    "# --- SETUP ---\n",
    "my_hf_token = \"hf_XXXXXXXXXXXXXXXXXXXXXXX\" # PUT YOUR TOKEN HERE\n",
    "login(token=my_hf_token)\n",
    "hf_repo_name = \"Consscht/FlowerDiff\"\n",
    "\n",
    "# --- LOAD DATASET ---\n",
    "print(\"1. Attempting to load dataset...\", flush=True)\n",
    "\n",
    "if 'dataset' not in locals():\n",
    "    dataset = fo.load_dataset(\"generated_flowers_with_embeddings\")\n",
    "print(f\"   Dataset loaded. Size: {len(dataset)} samples.\", flush=True)\n",
    "\n",
    "# --- UPLOAD ---\n",
    "print(f\"2. Preparing to upload to: {hf_repo_name}...\", flush=True)\n",
    "\n",
    "try:\n",
    "    # Attempt Native Method (FiftyOne v0.23+)\n",
    "    dataset.push_to_hub(\n",
    "        repo_id=hf_repo_name,\n",
    "        private=False,\n",
    "        dataset_type=\"image\"\n",
    "    )\n",
    "    print(\"3. Success (Native)! Our dataset is now published \")\n",
    "\n",
    "except AttributeError:\n",
    "    print(\"   Switching to Manual Export & Upload compatibility mode...\")\n",
    "\n",
    "    # Fallback: Expert & Upload Manually\n",
    "    export_folder = \"./flower_dataset_export\"\n",
    "    \n",
    "    # A. Export to disk\n",
    "    dataset.export(\n",
    "        export_dir=export_folder,\n",
    "        dataset_type=fo.types.FiftyOneDataset,\n",
    "        export_media=True,\n",
    "        overwrite=True\n",
    "    )\n",
    "    \n",
    "    # B. Upload via HfApi\n",
    "    api = HfApi(token=my_hf_token)\n",
    "    api.create_repo(repo_id=hf_repo_name, repo_type=\"dataset\", exist_ok=True)\n",
    "    api.upload_folder(\n",
    "        folder_path=export_folder,\n",
    "        repo_id=hf_repo_name,\n",
    "        repo_type=\"dataset\",\n",
    "    )\n",
    "    print(\"3. Success (Manual)! Our dataset is now published \")\n",
    "\n",
    "print(f\"View it here: https://huggingface.co/datasets/{hf_repo_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIQ-lKivsOT-"
   },
   "source": [
    "## Bonus -- \"MNIST\" idk classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B2fijGTQv_Nw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torchvision.utils import save_image\n",
    "import fiftyone as fo\n",
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "project_root = Path.cwd()\n",
    "if str(project_root / \"utilis\" / \"utils\") not in sys.path:\n",
    "    sys.path.append(str(project_root / \"utilis\" / \"utils\"))\n",
    "\n",
    "import utils\n",
    "from utils import ClassicLeNet5 \n",
    "import UNet_utils\n",
    "import ddpm_utils\n",
    "\n",
    "# --- 1. SETUP & CONFIG ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "THRESHOLD = 0.8         \n",
    "N_SAMPLES = 100          # How many images to generate\n",
    "OUT_DIR = Path(\"generated_mnist_bonus\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- 2. LOAD MODELS ---\n",
    "\n",
    "# A. Load the Trained IDK Classifier\n",
    "classifier = ClassicLeNet5(num_classes=11)\n",
    "classifier_path = \"best_lenet_idk.pth\"\n",
    "\n",
    "if Path(classifier_path).exists():\n",
    "    classifier.load_state_dict(torch.load(classifier_path, map_location=device))\n",
    "    print(f\"Loaded IDK Classifier from {classifier_path}\")\n",
    "else:\n",
    "    print(f\"WARNING: Classifier checkpoint '{classifier_path}' not found!\")\n",
    "\n",
    "classifier.to(device)\n",
    "classifier.eval()\n",
    "\n",
    "# B. Load the UNet (Diffusion) Model\n",
    "try:\n",
    "    model = UNet_utils.UNet(\n",
    "        T=400, img_ch=1, img_size=28, \n",
    "        down_chs=(64, 64, 128),  \n",
    "        t_embed_dim=8, \n",
    "        c_embed_dim=10         \n",
    "    ).to(device)\n",
    "\n",
    "    mnist_weights = \"MNIST_DIFF.pth\"\n",
    "    if Path(mnist_weights).exists():\n",
    "        state_dict = torch.load(mnist_weights, map_location=device)\n",
    "        new_state_dict = {}\n",
    "        for k, v in state_dict.items():\n",
    "            if k.startswith(\"_orig_mod.\"):\n",
    "                new_state_dict[k.replace(\"_orig_mod.\", \"\")] = v\n",
    "            else:\n",
    "                new_state_dict[k] = v\n",
    "        model.load_state_dict(new_state_dict)\n",
    "        print(f\"Loaded Diffusion Weights from {mnist_weights}\")\n",
    "    else:\n",
    "        print(f\"WARNING: {mnist_weights} not found. Using random weights.\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error loading model: {e}\") \n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Setup DDPM for generation\n",
    "B = torch.linspace(0.0001, 0.02, 400).to(device)\n",
    "ddpm = ddpm_utils.DDPM(B, device)\n",
    "\n",
    "# --- 3. DEFINE PREDICTION \"IDK\" FUNCTION ---\n",
    "def predict_with_idk(image, model, threshold):\n",
    "    with torch.inference_mode():\n",
    "        logits = model(image)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        max_prob, pred_idx = torch.max(probs, dim=1)\n",
    "        \n",
    "        idx = pred_idx.item()\n",
    "        \n",
    "        if idx == 10:\n",
    "            return \"IDK\", max_prob.item()\n",
    "        \n",
    "        return str(idx), max_prob.item()\n",
    "\n",
    "# --- 4. GENERATE, CLASSIFY & BUILD DATASET ---\n",
    "\n",
    "# Initialize FiftyOne Dataset\n",
    "dataset_name = \"mnist_idk_experiment\"\n",
    "if dataset_name in fo.list_datasets():\n",
    "    fo.delete_dataset(dataset_name)\n",
    "dataset = fo.Dataset(name=dataset_name)\n",
    "\n",
    "print(f\"Generating {N_SAMPLES} digits and classifying...\")\n",
    "\n",
    "samples = []\n",
    "\n",
    "for i in range(N_SAMPLES):\n",
    "    try:\n",
    "        # Create a random digit class condition (0-9)\n",
    "        digit = np.random.randint(0, 10)\n",
    "        c_digit = torch.zeros(1, 10).to(device)\n",
    "        c_digit[0, digit] = 1.0 \n",
    "        \n",
    "        # Generate Image (x_gen is [-1, 1])\n",
    "        x_gen, _ = ddpm_utils.sample_w(\n",
    "            model, \n",
    "            ddpm, \n",
    "            (1, 28, 28), \n",
    "            400, \n",
    "            c_digit, \n",
    "            device, \n",
    "            w_tests=[5.0] \n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Generation failed at idx {i}: {e}\")\n",
    "        break\n",
    "\n",
    "    # B. Classify\n",
    "    # 1. Map from [-1, 1] to [0, 1]\n",
    "    img_01 = (x_gen.clamp(-1, 1) + 1) / 2.0\n",
    "\n",
    "    # --- IMPORTAN: Fix Gray Backgrounds ---\n",
    "    # The model generates gray backgrounds that hurt classification.\n",
    "    # Shift min to 0 and max to 1 to fix \"gray\" backgrounds\n",
    "    # This acts as a dynamic contrast stretch\n",
    "    img_01 = (img_01 - img_01.min()) / (img_01.max() - img_01.min())\n",
    "    \n",
    "    # 2. Normalize for LeNet\n",
    "    # Training used transforms.Normalize((0.1307,), (0.3081,))\n",
    "    # which calculates: (input - mean) / std\n",
    "    # 'img_01' is our [0,1] input.\n",
    "    img_norm = (img_01 - 0.1307) / 0.3081\n",
    "    \n",
    "    label, confidence = predict_with_idk(img_norm, classifier, THRESHOLD)\n",
    "\n",
    "    # C. Save Image to Disk\n",
    "    # Save the normalized-looking image for humans, or the raw?\n",
    "    # Usually we save the [0,1] image.\n",
    "    fp = OUT_DIR / f\"mnist_{i:04d}.png\"\n",
    "    save_image(img_01, fp)\n",
    "\n",
    "    # D. Create FiftyOne Sample\n",
    "    sample = fo.Sample(filepath=str(fp))\n",
    "\n",
    "    # Store the prediction\n",
    "    sample[\"prediction\"] = fo.Classification(\n",
    "        label=label,\n",
    "        confidence=confidence\n",
    "    )\n",
    "    sample[\"ground_truth\"] = fo.Classification(label=str(digit))\n",
    "\n",
    "    if label == \"IDK\":\n",
    "        sample.tags.append(\"idk_predicted\")\n",
    "    else:\n",
    "        sample.tags.append(\"digit_predicted\")\n",
    "        # Check if correct\n",
    "        if str(digit) == label:\n",
    "             sample.tags.append(\"correct\")\n",
    "        else:\n",
    "             sample.tags.append(\"wrong\")\n",
    "\n",
    "    samples.append(sample)\n",
    "\n",
    "# Add samples to dataset\n",
    "if samples:\n",
    "    dataset.add_samples(samples)\n",
    "    dataset.save()\n",
    "    print(f\"Done! Created dataset '{dataset_name}' with {len(samples)} samples.\")\n",
    "    \n",
    "    # --- 5. VISUALIZE ---\n",
    "    session = fo.launch_app(dataset)\n",
    "else:\n",
    "    print(\"No samples generated.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOWWCDlFhP5ZutyzmVTRqV3",
   "gpuType": "T4",
   "mount_file_id": "1c0-Ahw6cQAmC8TwUy9hxz3PxVToRvlm8",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pointllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
